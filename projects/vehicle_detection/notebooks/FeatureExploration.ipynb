{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "!jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('PrepData')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from vehicle_detector.descriptors.hog import HOG\n",
    "from vehicle_detector.descriptors import color\n",
    "from vehicle_detector.utils import image_utils\n",
    "\n",
    "\n",
    "with open('../data/filtered_images_path.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "vehicle_images_path = data['vehicle_images']\n",
    "non_vehicle_images_path = data['non_vehicle_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_n_m_grid(data, cmap='gray', rows=4, cols=2, axis='off', image=True):\n",
    "    f, axes = plt.subplots(rows, cols, squeeze=False, figsize=(cols*4, rows*4))\n",
    "    f.tight_layout()\n",
    "    \n",
    "    for idx, datum in enumerate(data):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        if axis=='off':\n",
    "            axes[row, col].axis('off')\n",
    "        if image==True:\n",
    "            axes[row, col].imshow(datum, cmap=cmap, aspect=\"auto\")\n",
    "        else:\n",
    "            axes[row, col].plot(datum)\n",
    "            \n",
    "def cvt_bgr_rgb(img, cv_to_mpimg=True):\n",
    "    flag = cv2.COLOR_BGR2RGB\n",
    "    if not cv_to_mpimg:  # convert from mpimg to cv\n",
    "        flag = cv2.COLOR_RGB2BGR\n",
    "    return cv2.cvtColor(img, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(img, use_color_hist, hog_descriptor, hog_cspace):\n",
    "    \n",
    "    color_features = []\n",
    "    if use_color_hist and len(img.shape) > 2:\n",
    "        color_features = color.color_hist(img, nbins=32)\n",
    "    \n",
    "    if hog_cspace != 'BGR':\n",
    "        img = image_utils.convert_color(img, hog_cspace)\n",
    "\n",
    "    hog_features = hog_descriptor.get_features(img, feature_vec=True)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        hog_features = np.concatenate((hog_features[0], hog_features[1], hog_features[2]))\n",
    "    \n",
    "    return np.concatenate((hog_features, color_features))\n",
    "\n",
    "def extract_dataset_features(image_paths, use_color_hist, orients, n_pixels, n_cells, hog_cspace):\n",
    "\n",
    "    features = []\n",
    "    \n",
    "    for img_path in tqdm(image_paths, desc='Processing image', leave=False):\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img.shape[0] != 64 or img.shape[1] != 64:\n",
    "            img = cv2.resize(img, (64, 64))\n",
    "        \n",
    "        hog_descriptor = HOG(orients, n_pixels, n_cells)\n",
    "        \n",
    "        features.append(extract_features(img, use_color_hist, hog_descriptor, hog_cspace))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "opts_color_hist = [True, False]\n",
    "opts_orients = [9, 10, 12]\n",
    "opts_n_pixels= [(8,8), (12,12), (16,16)]\n",
    "opts_n_cells = [(2,2), (4,4)]\n",
    "opts_cspace = ['BGR2GRAY', 'BGR', 'BGR2HSV', 'BGR2YCrCb']\n",
    "\n",
    "# Get all possible combinations of the above options\n",
    "parameter_combinations = list(itertools.product(opts_color_hist, opts_orients, opts_n_pixels,\n",
    "                                           opts_n_cells, opts_cspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub sample of the dataset for parameter tuning\n",
    "EXPLORATION_DATASET_SIZE = 2000\n",
    "\n",
    "car_indices = np.random.randint(0, len(vehicle_images_path), size=EXPLORATION_DATASET_SIZE)\n",
    "non_car_indices = np.random.randint(0, len(non_vehicle_images_path), size=EXPLORATION_DATASET_SIZE)\n",
    "car_image_paths = list(vehicle_images_path[i] for i in car_indices)\n",
    "non_car_image_paths = list(non_vehicle_images_path[i] for i in non_car_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# Set number of parallel jobs for GridSearch\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "N_PARALLEL_JOBS = CPU_COUNT-2 if CPU_COUNT > 2 else 1\n",
    "\n",
    "\n",
    "params_stats = [] # Store calculated params here\n",
    "for params in tqdm(parameter_combinations, desc='Exploring params', unit='params'):\n",
    "    t = time.time()\n",
    "\n",
    "    car_features = extract_dataset_features(car_image_paths, params[0],\n",
    "                                            params[1], params[2], params[3], params[4])\n",
    "    non_car_features = extract_dataset_features(non_car_image_paths,params[0],\n",
    "                                            params[1], params[2], params[3], params[4])\n",
    "\n",
    "    t2 = time.time()\n",
    "    avg_extraction_time = round((t2 - t) / (2* EXPLORATION_DATASET_SIZE), 5)\n",
    "    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, non_car_features)).astype(np.float64)\n",
    "    \n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(non_car_features))))\n",
    "    \n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        random_state=rand_state)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    \n",
    "    # Apply the scaler to X\n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    # Create a classifier object\n",
    "    svr = svm.SVC(kernel='rbf')\n",
    "    # Parameters for gridsearch\n",
    "    parameters = {'C':[0.01, 0.1, 1, 10],\n",
    "                  'gamma':[0.01, 0.1, 1, 10, 'auto']\n",
    "                 }\n",
    "    # Initialize the grid search parameters & classifier\n",
    "    clf = GridSearchCV(svr, parameters, n_jobs=N_PARALLEL_JOBS)\n",
    "\n",
    "    t = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "   \n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred) * 100, 3)\n",
    "    \n",
    "    param_name = 'CSP_{cspace}_C{cells}_B{blocks}_O{orients}_Hist_{hist}'.format(\n",
    "                    hist=params[0], orients=params[1], cells=params[2],\n",
    "                    blocks=params[3], cspace=params[4])\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'num_features': len(car_features[0]),\n",
    "        'best_params': clf.best_params_,\n",
    "        'extraction_time': avg_extraction_time,\n",
    "        'training_time': round(t2 - t, 2),\n",
    "        'name': param_name\n",
    "    }\n",
    "    params_stats.append(stats)\n",
    "sorted(param_stats, key=lambda x: x['accuracy'], reverse=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "3f5c12dd0be54a70afd557e20710e56a": {
     "views": []
    },
    "53c1125b142e45e09582ca91acba58fc": {
     "views": []
    },
    "c7af20b06e224fc3a8bbe827e20caf3f": {
     "views": []
    },
    "caa04a7693f146cc90c412575e1f97dc": {
     "views": []
    },
    "d452e704184044e3ae8a178868aac400": {
     "views": []
    },
    "d58dfff2aac541b29df2e1dc33815e5d": {
     "views": []
    },
    "e5948fe1cd784668a6146d12ffad5c96": {
     "views": []
    },
    "e841fb27b2874f828f7c74249a74ed7b": {
     "views": []
    },
    "e90d9d1821a84b7fb46f2313df5559ff": {
     "views": []
    },
    "f1da908fd90d4e589b6ad5f7ff226c33": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "fcc2f212a8884b2e9fe0481478d10913": {
     "views": []
    },
    "fd89f016ae85465c85f78cde4bd422d7": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
