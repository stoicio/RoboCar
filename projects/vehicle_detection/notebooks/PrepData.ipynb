{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('PrepData')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = '../data/'\n",
    "\n",
    "from vehicle_detector.utils import fs_utils\n",
    "\n",
    "def download_datasets():\n",
    "    datasets = [\n",
    "        { 'url': 'https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip',\n",
    "          'download_dir': os.path.join(BASE_DATA_DIR, 'zips'),\n",
    "          'extract_dir': os.path.join(BASE_DATA_DIR, 'images')\n",
    "        },\n",
    "        { 'url': 'https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip',\n",
    "          'download_dir': os.path.join(BASE_DATA_DIR, 'zips'),\n",
    "          'extract_dir': os.path.join(BASE_DATA_DIR, 'images')\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        file_path = fs_utils.download_file(dataset['url'], dataset['download_dir'])\n",
    "        fs_utils.extract_zip(file_path, dataset['extract_dir'])\n",
    "\n",
    "        \n",
    "download_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(dir_path):\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return sorted(image_paths)\n",
    "\n",
    "def filter_similar_images(image_paths, intersection_thresh=750):\n",
    "    '''\n",
    "    Given a list of image paths, return a list of image paths with similar images removed\n",
    "    Implemented by calculating histogram for the two images and comparing them by calculating the \n",
    "    overlap between those two histograms. If the overlap is greater than the given threshold then\n",
    "    one of the similar image is ignore.\n",
    "    '''\n",
    "    curr_hist = None\n",
    "    prev_hist = None\n",
    "\n",
    "    filtered_images = [image_paths[0]]\n",
    "\n",
    "    prev_image = cv2.imread(image_paths[0])\n",
    "    curr_image = cv2.imread(image_paths[1])\n",
    "\n",
    "    prev_hist = cv2.calcHist([prev_image], [0,1,2], None, [256, 256, 256], [0,256, 0,256, 0,256])\n",
    "    curr_idx = 1\n",
    "\n",
    "\n",
    "    with tqdm(total=len(image_paths)) as pbar:\n",
    "        pbar.set_description('Filtering similar images')\n",
    "\n",
    "        while True: \n",
    "            curr_hist = cv2.calcHist([curr_image], [0,1,2], None, [256, 256, 256], [0,256, 0,256, 0,256])\n",
    "\n",
    "                intersection = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_INTERSECT)\n",
    "            if intersection > 750:\n",
    "                logger.debug('Ignoring %s - Score %d', os.path.basename(image_paths[curr_idx]), intersection)\n",
    "            else:\n",
    "                filtered_images.append(image_paths[curr_idx])\n",
    "                prev_image = curr_image\n",
    "                prev_hist = curr_hist\n",
    "            curr_idx += 1\n",
    "            \n",
    "            if curr_idx >= len(image_paths):\n",
    "                break\n",
    "            curr_image = cv2.imread(image_paths[curr_idx])\n",
    "            pbar.update(1)\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PrepData:Loaded 218 images from GTI_MiddleClose\n",
      "INFO:PrepData:Loaded 514 images from GTI_Far\n",
      "INFO:PrepData:Loaded 519 images from GTI_Left\n",
      "INFO:PrepData:Loaded 469 images from GTI_Right\n",
      "INFO:PrepData:Using 1720 images from a total of 2826 image in GTI Dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "GTI_data  = ['../data/images/vehicles/GTI_MiddleClose',\n",
    "             '../data/images/vehicles/GTI_Far',\n",
    "             '../data/images/vehicles/GTI_Left',\n",
    "             '../data/images/vehicles/GTI_Right']\n",
    "\n",
    "filtered_gti_images = []\n",
    "unfiltered_gti_images = []\n",
    "\n",
    "for data_path in tqdm(GTI_data, desc='GTI data'):\n",
    "    \n",
    "    this_path_images = get_image_paths(data_path)\n",
    "    unfiltered_gti_images.extend(this_path_images)\n",
    "    \n",
    "    # Filter Similar Images since dataset is from a video sequence\n",
    "    filtered_images = filter_similar_images(this_path_images)\n",
    "    filtered_gti_images.extend(filtered_images)\n",
    "    \n",
    "    logger.info('Loaded %d images from %s', len(filtered_images), os.path.basename(data_path))\n",
    "\n",
    "logger.info('Using %d images from a total of %d image in GTI Dataset',\n",
    "            len(filtered_gti_images), len(unfiltered_gti_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PrepData:Total Positive Samples 7686\n",
      "INFO:PrepData:Total Negative Samples 8968\n"
     ]
    }
   ],
   "source": [
    "non_vehicle_dirs = ['../data/images/non-vehicles/GTI',\n",
    "                   '../data/images/non-vehicles/Extras']\n",
    "\n",
    "filtered_vehicle_data = []\n",
    "unfiltered_vehicle_data = []\n",
    "\n",
    "kitti_vehicle_data = get_image_paths('../data/images/vehicles/KITTI_extracted')\n",
    "\n",
    "filtered_vehicle_data.extend(filtered_gti_images)\n",
    "filtered_vehicle_data.extend(kitti_vehicle_data)\n",
    "\n",
    "unfiltered_vehicle_data.extend(unfiltered_gti_images)\n",
    "unfiltered_vehicle_data.extend(kitti_vehicle_data)\n",
    "\n",
    "\n",
    "all_non_vehicle_data = get_image_paths(non_vehicle_dirs[0])\n",
    "all_non_vehicle_data.extend(get_image_paths(non_vehicle_dirs[1]))\n",
    "\n",
    "logger.info('Total Positive Samples %s (Filtered)', len(filtered_vehicle_data))\n",
    "logger.info('Total Positive Samples %s (Not Filtered)', len(unfiltered_vehicle_data))\n",
    "logger.info('Total Negative Samples %s (Not Filtered)', len(all_non_vehicle_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_paths = {\n",
    "    'vehicle_images': filtered_vehicle_data,\n",
    "    'non_vehicle_images': all_non_vehicle_data\n",
    "}\n",
    "\n",
    "with open('../data/filtered_images_path.json', 'w') as fp:\n",
    "    json.dump(file_paths, fp)\n",
    "\n",
    "file_paths['vehicle_images'] = unfiltered_vehicle_data\n",
    "\n",
    "with open('../data/unfiltered_images_path.json', 'w') as fp:\n",
    "    json.dump(file_paths, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
